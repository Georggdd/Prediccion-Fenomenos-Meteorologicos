# Entrenamiento de modelos

Explicaci√≥n de los modelos usados, configuraci√≥n, validaci√≥n y m√©tricas.

Ejemplo:
- √Årboles de decisi√≥n para clasificaci√≥n.
- Modelos de regresi√≥n para predicci√≥n de magnitud.
- LSTM para series temporales.
- Dividir datos en entrenamiento y test.
- Uso de TensorFlow/Keras.

# Explicaci√≥n del 1er notebook en jupyter de prueba:

# Celda 1 - Importar librer√≠as necesarias
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LinearRegression
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Explicaci√≥n celda
 Librer√≠as de manipulaci√≥n de datos:
| `pandas` (`pd`) | Sirve para leer, limpiar y manipular datos (como tablas de Excel). Es el alma del an√°lisis de datos en Python. |
| `numpy` (`np`)  | Trabaja con arrays y operaciones matem√°ticas. Muy √∫til para c√°lculos num√©ricos


Librer√≠as de Machine Learning (aprendizaje autom√°tico):
| `train_test_split`       | Sirve para dividir los datos en **entrenamiento y prueba** (algo esencial para entrenar modelos).                                |
| `DecisionTreeClassifier` | Un modelo de clasificaci√≥n basado en √°rboles de decisi√≥n (lo usaremos para clasificar eventos extremos como sequ√≠a o no sequ√≠a). |
| `LinearRegression`       | Modelo de regresi√≥n (lo usaremos para predecir **valores num√©ricos**, como temperatura o precipitaci√≥n).                         |


Librer√≠as de Deep Learning (redes neuronales):
| `Sequential`    | Es una forma simple de construir redes neuronales en **TensorFlow/Keras**.                           |
| `LSTM`          | Tipo de red neuronal dise√±ada para **series temporales**, como los datos meteorol√≥gicos.             |
| `Dense`         | Capa de neuronas tradicional (la m√°s b√°sica).                                                        |
| `EarlyStopping` | Detiene el entrenamiento autom√°ticamente si el modelo ya no mejora (evita que ‚Äúmemorice‚Äù los datos). |


Librer√≠as de visualizaci√≥n:
| `matplotlib.pyplot` (`plt`) | Sirve para hacer gr√°ficos y visualizar datos y resultados. |

# Resultados
No imprime nada, solo carga las herramientas. Si no da error, est√° todo en √≥rden.

-------------------------------------------------------------------------------------------------------------------------------

# Celda 2 - Cargar datos limpios (ajusta las rutas a tus archivos)
df_diarios = pd.read_csv('src/data/limpios/AEMET/alcantarilla/diarios/diarios.csv')
df_mensuales = pd.read_csv('src/data/limpios/AEMET/alcantarilla/mensuales-anuales/mensuales.csv')
df_anuales = pd.read_csv('src/data/limpios/AEMET/alcantarilla/mensuales-anuales/anuales.csv')

print("Datos diarios cargados:", df_diarios.shape)
print("Datos mensuales cargados:", df_mensuales.shape)
print("Datos anuales cargados:", df_anuales.shape)

# Explicaci√≥n celda
La celda 2 es clave porque carga los datos meteorol√≥gicos limpios que se van a usar para entrenar los modelos. 
Lee 3 archivos .csv usando pandas y los convierte en tablas (DataFrames) en Python:
| Variable Python | Contenido                      |
| --------------- | ------------------------------ |
| `df_diarios`    | Datos meteorol√≥gicos diarios   |
| `df_mensuales`  | Datos meteorol√≥gicos mensuales |
| `df_anuales`    | Datos meteorol√≥gicos anuales   |
Adem√°s, muestra cu√°ntas filas y columnas tiene cada conjunto de datos.

# Resultados
Y Resultados: Datos diarios cargados: (3830, 25)
Datos mensuales cargados: (132, 44)
Datos anuales cargados: (11, 44)

# Explicaci√≥n resultados
Dataset	        Filas (ejemplos)	Columnas (variables)	Significado
df_diarios	    3830	            25	                    Tienes 3830 d√≠as de datos (por ejemplo, desde 2014 a 2024) y                                                           25 variables como temperatura, precipitaci√≥n, humedad, etc.
df_mensuales	132             	44	                    132 meses de datos, es decir, 11 a√±os √ó 12 meses y 44 variables.
df_anuales	    11	                44	                    11 a√±os (probablemente desde 2013 a 2023) y 44 variables.


Si sale este mensaje sin errores, es que los archivos se han cargado correctamente y las rutas est√°n bien.
Ahora ya est√°n los datos cargados en memoria y listos para analizarlos o entrenar modelos.
-------------------------------------------------------------------------------------------------------------------------------

# Celda 3 - Exploraci√≥n r√°pida de los datos diarios
print(df_diarios.head())
print(df_diarios.info())

# Explicaci√≥n celda
Esta celda es la primera en la que observamos directamente el contenido y la estructura del dataset diario.

df_diarios.head()
Muestra las primeras 5 filas del DataFrame df_diarios. Esto te da una idea general del contenido del archivo: qu√© columnas hay, qu√© tipo de valores, si parecen correctos, etc.

df_diarios.info()
Muestra un resumen t√©cnico del DataFrame:
N√∫mero total de filas (3830)
Lista de columnas
Cu√°ntos valores faltan por columna
Tipo de dato de cada columna (float64, int64, object...)

# Resultados
      fecha  indicativo                    nombre provincia  altitud  tmed  \
0  2015-01-01        7228  ALCANTARILLA, BASE AEREA    MURCIA       75   8.6   
1  2015-01-02        7228  ALCANTARILLA, BASE AEREA    MURCIA       75   8.4   
2  2015-01-03        7228  ALCANTARILLA, BASE AEREA    MURCIA       75   9.9   
3  2015-01-04        7228  ALCANTARILLA, BASE AEREA    MURCIA       75  12.2   
4  2015-01-05        7228  ALCANTARILLA, BASE AEREA    MURCIA       75   9.6   

   prec  tmin horatmin  tmax  ...  sol  presMax  horaPresMax  presMin  \
0   0.0   1.5   Varias  15.8  ...  7.3   1028.6           10   1020.8   
1   0.0  -0.4    07:20  17.2  ...  9.0   1030.9           10   1028.1   
2   0.0  -0.4    05:40  20.2  ...  9.1   1030.5           00   1025.9   
3   0.0   2.6    07:15  21.8  ...  9.0   1026.4           00   1020.9   
4   0.0   1.4    07:00  17.9  ...  9.0   1023.2           09   1018.9   

  horaPresMin  hrMedia  hrMax horaHrMax  hrMin horaHrMin  
0          00       67     90     23:10     45     12:20  
1          05       68     97     06:30     31     14:50  
2          18       63     94     06:00     32     14:00  
3          16       48     84    Varias     19     14:40  
4          24       74     97     23:59     50     13:00  

[5 rows x 25 columns]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 3830 entries, 0 to 3829
Data columns (total 25 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   fecha        3830 non-null   object 
 1   indicativo   3830 non-null   int64  
 2   nombre       3830 non-null   object 
 3   provincia    3830 non-null   object 
 4   altitud      3830 non-null   int64  
 5   tmed         3830 non-null   float64
 6   prec         3724 non-null   float64
 7   tmin         3830 non-null   float64
 8   horatmin     3830 non-null   object 
 9   tmax         3830 non-null   float64
 10  horatmax     3830 non-null   object 
 11  dir          3797 non-null   float64
 12  velmedia     3807 non-null   float64
 13  racha        3797 non-null   float64
 14  horaracha    3797 non-null   object 
 15  sol          3801 non-null   float64
 16  presMax      3829 non-null   float64
 17  horaPresMax  3829 non-null   object 
 18  presMin      3829 non-null   float64
 19  horaPresMin  3825 non-null   object 
 20  hrMedia      3830 non-null   int64  
 21  hrMax        3830 non-null   int64  
 22  horaHrMax    3830 non-null   object 
 23  hrMin        3830 non-null   int64  
 24  horaHrMin    3830 non-null   object 
dtypes: float64(10), int64(5), object(10)
memory usage: 748.2+ KB
None

# Explicaci√≥n resultados
‚úÖ Filas y columnas
Hay 3830 filas ‚Üí son 3830 d√≠as de datos.
Hay 25 columnas, que representan variables meteorol√≥gicas por d√≠a.

‚úÖ Ejemplos de columnas y sus significados
Columna	Descripci√≥n
fecha	D√≠a del dato
tmed	Temperatura media del d√≠a
prec	Precipitaci√≥n en mm
tmin, tmax	Temperaturas m√≠nima y m√°xima
sol	Horas de sol
presMax, presMin	Presiones m√°xima y m√≠nima
hrMedia, hrMax, hrMin	Humedad relativa media, m√°xima y m√≠nima
dir, velmedia, racha	Direcci√≥n del viento, velocidad media y racha m√°xima

Algunas columnas como horatmin, horaPresMin, etc., tienen la hora del d√≠a en que ocurri√≥ el valor m√≠nimo o m√°ximo.

‚ö†Ô∏è Valores faltantes (missing values)
En el resumen vemos que algunas columnas no tienen los 3830 valores completos:

Columna	    Valores no nulos	Faltantes
prec	    3724	106
dir	        3797	33
velmedia	3807	23
sol	        3801	29

Estas faltas no son muchas, pero conviene tenerlo en cuenta para m√°s adelante: podremos decidir si rellenarlas, eliminarlas o usar alguna t√©cnica especial.

üßÆ Tipos de datos
object ‚Üí texto, fechas o horas.
float64 ‚Üí n√∫meros con decimales (temperatura, presi√≥n...).
int64 ‚Üí enteros (altitud, humedad...).

M√°s adelante convertiremos fecha al tipo datetime para trabajar con el tiempo.

Ahora que se sabe qu√© contienen los datos diarios, podemos:
- Analizar c√≥mo se comportan las variables en el tiempo.
- Entrenar modelos para predecir cosas como temperatura, lluvia o humedad.
- Buscar correlaciones entre columnas.

-------------------------------------------------------------------------------------------------------------------------------


# Celda 4 - Preparar datos para un modelo simple:  
# Queremos predecir si llovi√≥ o no (variable 'prec' > 0)

# Crear columna 'lluvia' binaria: 1 si lluvia > 0, 0 si no
df_diarios['lluvia'] = (df_diarios['prec'] > 0).astype(int)

# Elegimos caracter√≠sticas (features) num√©ricas para entrenar
features = ['tmed', 'tmin', 'tmax', 'velmedia', 'racha', 'presMax', 'presMin', 'hrMedia', 'sol']
X = df_diarios[features].fillna(0)  # Rellenar nulos con 0 para simplificar
y = df_diarios['lluvia']

print("Caracter√≠sticas seleccionadas:", X.columns)

# Explicaci√≥n celda
üéØ Objetivo:
Predecir si llovi√≥ o no en un d√≠a usando algunas variables meteorol√≥gicas.

‚úÖ Paso 1: Crear la variable objetivo lluvia
df_diarios['lluvia'] = (df_diarios['prec'] > 0).astype(int)
Esto crea una nueva columna llamada lluvia que tiene:
- 1 si s√≠ llovi√≥ (prec > 0)
- 0 si no llovi√≥

üîç Esto transforma un problema de regresi√≥n (predecir cu√°nto llueve) en uno de clasificaci√≥n binaria: predecimos s√≠ o no.

‚úÖ Paso 2: Selecci√≥n de caracter√≠sticas (features)
features = ['tmed', 'tmin', 'tmax', 'velmedia', 'racha', 'presMax', 'presMin', 'hrMedia', 'sol']

Estas son las variables meteorol√≥gicas num√©ricas que usaremos para predecir la lluvia.

Variable	 Significado
tmed	     Temperatura media
tmin	     Temperatura m√≠nima
tmax	     Temperatura m√°xima
velmedia     Velocidad media del viento
racha	     Racha m√°xima del viento
presMax	     Presi√≥n atmosf√©rica m√°xima
presMin	     Presi√≥n atmosf√©rica m√≠nima
hrMedia	     Humedad relativa media
sol  	     Horas de sol del d√≠a

‚úÖ Paso 3: Preparar X e y
X = df_diarios[features].fillna(0)
y = df_diarios['lluvia']

- X son tus variables predictoras.
Se rellenan los valores NaN (faltantes) con 0 para evitar errores (esto es una soluci√≥n r√°pida, aunque no siempre ideal).

- y es la etiqueta: si llovi√≥ (1) o no (0).

# Resultados
Caracter√≠sticas seleccionadas: Index(['tmed', 'tmin', 'tmax', 'velmedia', 'racha', 'presMax', 'presMin',
       'hrMedia', 'sol'],
      dtype='object')

# Explicaci√≥n resultados
Muestra que todo ha ido bien y que las columnas han sido seleccionadas correctamente.

Ahora los datos est√°n listos para entrenar un modelo de predicci√≥n.
El siguiente paso ser√° hacer el split en train/test y entrenar un modelo de clasificaci√≥n, como un √°rbol de decisi√≥n üå≥.
-------------------------------------------------------------------------------------------------------------------------------

# Celda 5 - Dividir los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Tama√±o de entrenamiento:", X_train.shape)
print("Tama√±o de prueba:", X_test.shape)

# Explicaci√≥n celda
En esta celda 5 estamos dividiendo los datos para poder entrenar y evaluar el modelo correctamente. Vamos a ver con claridad qu√© significa cada paso.

üéØ Objetivo de esta celda
Separar el conjunto de datos (X, y) en:

- Conjunto de entrenamiento (train) ‚Üí Para entrenar el modelo.
- Conjunto de prueba (test) ‚Üí Para evaluar qu√© tan bien generaliza el modelo a datos nuevos.

‚úÖ C√≥digo l√≠nea a l√≠nea
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

Explicaci√≥n:
X = datos de entrada (features seleccionadas).
y = etiqueta que queremos predecir (llovi√≥ o no).

test_size=0.2 ‚Üí Reservamos un 20% de los datos para pruebas.
random_state=42 ‚Üí Semilla para obtener siempre la misma divisi√≥n (importante para reproducibilidad).

Resultado:
X_train: 80% de los datos (3.064 d√≠as).
X_test: 20% de los datos (766 d√≠as).

‚úÖ Por qu√© es importante esta divisi√≥n
Sin esta separaci√≥n:
- El modelo podr√≠a ‚Äúmemorizar‚Äù los datos en lugar de aprender patrones generales.
- No tendr√≠amos forma de saber si realmente funciona bien con datos nuevos.

# Resultados
Tama√±o de entrenamiento: (3064, 9)
Tama√±o de prueba: (766, 9)

# Explicaci√≥n resultados
Cada conjunto contiene 9 columnas (las variables meteorol√≥gicas), y el n√∫mero de filas corresponde a los d√≠as.

En el siguiente paso empezamos con el modelo de √°rbol de decisi√≥n

-------------------------------------------------------------------------------------------------------------------------------

# Celda 6 - Entrenar un √Årbol de Decisi√≥n para clasificaci√≥n de lluvia
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)

score_train = clf.score(X_train, y_train)
score_test = clf.score(X_test, y_test)

print(f"Precisi√≥n en entrenamiento: {score_train:.2f}")
print(f"Precisi√≥n en prueba: {score_test:.2f}")

# Explicaci√≥n
Esta celda 6 marca el inicio del modelado predictivo, y usas un √Årbol de Decisi√≥n para predecir si va a llover o no.

üéØ Objetivo
Entrenar un modelo de clasificaci√≥n que prediga la probabilidad de lluvia (1 = llovi√≥, 0 = no llovi√≥) usando las variables meteorol√≥gicas.

üß† ¬øQu√© es un √Årbol de Decisi√≥n?
Un √°rbol de decisi√≥n es como un flujo de preguntas que se hace el modelo para decidir si un caso pertenece a una clase u otra. Ejemplo:

¬øpresi√≥n baja?
    ‚îî‚îÄ S√≠ ‚Üí ¬øtemperatura baja?
        ‚îî‚îÄ S√≠ ‚Üí Probabilidad de lluvia alta

‚úÖ C√≥digo explicado paso a paso
clf = DecisionTreeClassifier(random_state=42)

Crea el modelo de √°rbol de decisi√≥n.
random_state=42 asegura resultados reproducibles.
----
clf.fit(X_train, y_train)

El modelo se entrena con el 80% de los datos (X_train, y_train).
---

score_train = clf.score(X_train, y_train)
score_test = clf.score(X_test, y_test)

score() calcula la precisi√≥n: proporci√≥n de predicciones correctas.
En entrenamiento (score_train) ‚Üí qu√© tan bien predice los datos con los que se entren√≥.
En prueba (score_test) ‚Üí qu√© tan bien predice datos nuevos.

# Resultados
Precisi√≥n en entrenamiento: 1.00
Precisi√≥n en prueba: 0.84

# Explicaci√≥n resultados 
1.00 en entrenamiento: el modelo memoriz√≥ los datos (¬°cuidado! esto puede ser sobreajuste).
0.84 en prueba: acierta el 84% de los d√≠as nuevos ‚Üí buen resultado, pero puede mejorar con m√°s limpieza o modelos m√°s complejos.

*S√≠. Cuando un modelo tiene 100% de precisi√≥n en entrenamiento pero menos en test, probablemente ha aprendido los datos ‚Äúde memoria‚Äù en vez de generalizar. A√∫n as√≠, 0.84 en test no est√° mal para un primer intento.*
-------------------------------------------------------------------------------------------------------------------------------

# Celda 7 - Entrenar un modelo de regresi√≥n para predecir la cantidad de lluvia (prec)

# Usamos solo d√≠as con lluvia para este modelo
precip_dias = df_diarios[df_diarios['prec'] > 0]
X_prec = precip_dias[features].fillna(0)
y_prec = precip_dias['prec']

X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_prec, y_prec, test_size=0.2, random_state=42)

reg = LinearRegression()
reg.fit(X_train_reg, y_train_reg)

score_reg_train = reg.score(X_train_reg, y_train_reg)
score_reg_test = reg.score(X_test_reg, y_test_reg)

print(f"R2 en entrenamiento (precipitaci√≥n): {score_reg_train:.2f}")
print(f"R2 en prueba (precipitaci√≥n): {score_reg_test:.2f}")

# Explicaci√≥n
En esta celda 7 estamos pasando de una clasificaci√≥n a una regresi√≥n: ahora no queremos saber si llueve, sino cu√°nto llueve.

üéØ Objetivo
Predecir la cantidad exacta de lluvia (prec) solo en los d√≠as en que llovi√≥ (prec > 0), usando un modelo de regresi√≥n lineal.

üß† ¬øQu√© es la regresi√≥n lineal?
Es un modelo que intenta ajustar una l√≠nea (o plano, o hiperplano) que relacione las variables independientes (tmed, presMax, etc.) con una variable dependiente (prec en este caso).

Matem√°ticamente:
prec ‚âà b0 + b1*tmed + b2*tmin + ... + b9*sol

 C√≥digo explicado
precip_dias = df_diarios[df_diarios['prec'] > 0]

Filtra el DataFrame para quedarse solo con los d√≠as lluviosos.
-----

X_prec = precip_dias[features].fillna(0)
y_prec = precip_dias['prec']

Crea las variables X (caracter√≠sticas) e y (etiqueta a predecir = cantidad de lluvia).
----

X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(...)

Divide los datos lluviosos en entrenamiento y prueba.
----

reg = LinearRegression()
reg.fit(X_train_reg, y_train_reg)

Crea y entrena un modelo de regresi√≥n lineal.
----

score_reg_train = reg.score(X_train_reg, y_train_reg)
score_reg_test = reg.score(X_test_reg, y_test_reg)

Calcula el R¬≤ (R cuadrado), que indica qu√© proporci√≥n de la variabilidad del prec puede explicarse por las variables independientes.

üßÆ ¬øQu√© nos dice el valor de R¬≤?
R¬≤ valor	Significado
1.00	Predicci√≥n perfecta (casi imposible en el mundo real)
0.90	Muy buen modelo
0.50	Modelo decente
0.10	Modelo d√©bil
< 0.00	Peor que predecir la media
-----

# Resultados 
R2 en entrenamiento (precipitaci√≥n): 0.17
R2 en prueba (precipitaci√≥n): 0.07

# Explicaci√≥n resultados
0.17 en entrenamiento ‚Üí el modelo explica solo el 17% de la variabilidad de la lluvia en los datos que ha visto.
0.07 en test ‚Üí solo el 7% en datos nuevos.

Esto nos dice que:
El modelo no predice bien la cantidad de lluvia.
Las relaciones entre las variables y la lluvia no son lineales.

Posiblemente necesitas:
Modelos no lineales (Random Forest, XGBoost, redes neuronales‚Ä¶)
M√°s variables (ej. humedad relativa, d√≠as anteriores, acumulados‚Ä¶)
Datos m√°s limpios (sin outliers, con normalizaci√≥n...)

-------------------------------------------------------------------------------------------------------------------------------


# Celda 8 - Preparar datos para LSTM (serie temporal)

# Vamos a usar la temperatura media diaria para predecir la siguiente

# Ordenar por fecha
df_diarios = df_diarios.sort_values('fecha')

# Seleccionar la columna para la serie temporal
serie = df_diarios['tmed'].fillna(method='ffill').values  # Rellenar con el √∫ltimo valor v√°lido

# Normalizar (escalar) la serie entre 0 y 1 para que LSTM funcione mejor
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))
serie_scaled = scaler.fit_transform(serie.reshape(-1,1))

# Funci√≥n para crear secuencias (ventanas deslizantes)
def crear_secuencias(data, pasos=5):
    X, y = [], []
    for i in range(len(data) - pasos):
        X.append(data[i:i+pasos])
        y.append(data[i+pasos])
    return np.array(X), np.array(y)

pasos = 5
X_lstm, y_lstm = crear_secuencias(serie_scaled, pasos)

# Dividir en entrenamiento y prueba
split = int(len(X_lstm) * 0.8)
X_train_lstm, X_test_lstm = X_lstm[:split], X_lstm[split:]
y_train_lstm, y_test_lstm = y_lstm[:split], y_lstm[split:]

print("Formas de los datos LSTM:", X_train_lstm.shape, y_train_lstm.shape)

# Explicaci√≥n

Esta celda est√° dedicada a preparar los datos para alimentar un modelo LSTM que prediga la temperatura media diaria del d√≠a siguiente a partir de las temperaturas de d√≠as anteriores.

1. Ordenar por fecha
df_diarios = df_diarios.sort_values('fecha')

Aseguramos que la serie temporal est√© ordenada cronol√≥gicamente para que la secuencia tenga sentido.

2. Seleccionar la serie temporal a predecir
serie = df_diarios['tmed'].fillna(method='ffill').values

Se escoge la columna tmed (temperatura media diaria).
Para los valores nulos, se rellena con el √∫ltimo valor v√°lido anterior (forward fill). Esto es importante para no dejar huecos que rompan la secuencia.
(Nota: aparece un warning indicando que fillna(method='ffill') est√° obsoleto, es mejor usar directamente df_diarios['tmed'].ffill().)

3. Normalizar los datos
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))
serie_scaled = scaler.fit_transform(serie.reshape(-1,1))

Se escala la serie para que sus valores est√©n entre 0 y 1. Esto es fundamental para que la red neuronal LSTM aprenda mejor y de forma m√°s estable, porque las activaciones funcionan mejor en rangos reducidos.

4. Crear secuencias con ventanas deslizantes
def crear_secuencias(data, pasos=5):
    X, y = [], []
    for i in range(len(data) - pasos):
        X.append(data[i:i+pasos])
        y.append(data[i+pasos])
    return np.array(X), np.array(y)
pasos = 5
X_lstm, y_lstm = crear_secuencias(serie_scaled, pasos)

Aqu√≠ se crea la estructura de datos para el LSTM:

- asos=5 indica que usaremos las temperaturas de 5 d√≠as consecutivos para predecir la temperatura del d√≠a siguiente.
- X_lstm ser√° un array de secuencias de 5 d√≠as (ventanas de entrada).
- y_lstm ser√° el valor objetivo (temperatura del d√≠a siguiente).

Por ejemplo, para la posici√≥n i, X[i] son las temperaturas desde el d√≠a i hasta i+4, y y[i] es la temperatura del d√≠a i+5.

5. Dividir los datos en entrenamiento y prueba
split = int(len(X_lstm) * 0.8)
X_train_lstm, X_test_lstm = X_lstm[:split], X_lstm[split:]
y_train_lstm, y_test_lstm = y_lstm[:split], y_lstm[split:]

Se utiliza un 80% de los datos para entrenar y el 20% restante para evaluar el modelo.
Se respetan las secuencias temporales, no se mezclan datos para evitar "mirar al futuro".

6. Imprimir las formas (shapes) de los datos
print("Formas de los datos LSTM:", X_train_lstm.shape, y_train_lstm.shape)

# Resultados
Formas de los datos LSTM: (3060, 5, 1) (3060, 1)

C:\Users\georg\AppData\Local\Temp\ipykernel_8780\3971590742.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  serie = df_diarios['tmed'].fillna(method='ffill').values  # Rellenar con el √∫ltimo valor v√°lido

# Explicaci√≥n resultados
Esto significa que:

Hay 3060 muestras para entrenamiento.
Cada muestra de entrada X_train_lstm tiene 5 pasos temporales (d√≠as), y 1 caracter√≠stica (temperatura).
Cada etiqueta y_train_lstm es un valor √∫nico (temperatura siguiente).

(Nota: aparece un warning indicando que fillna(method='ffill') est√° obsoleto, es mejor usar directamente df_diarios['tmed'].ffill().) El warning sobre fillna es menor y puede corregirse para futuras versiones.

-------------------------------------------------------------------------------------------------------------------------------


# Celda 9 - Crear y entrenar modelo LSTM

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

model = Sequential()
model.add(Input(shape=(pasos, 1)))   # Capa de entrada expl√≠cita para evitar warning
model.add(LSTM(50))                  # Activaci√≥n por defecto 'tanh'
model.add(Dense(1))

model.compile(optimizer='adam', loss='mse')

early_stop = EarlyStopping(monitor='val_loss', patience=5)

history = model.fit(
    X_train_lstm, y_train_lstm,
    epochs=50,
    batch_size=32,
    validation_data=(X_test_lstm, y_test_lstm),
    callbacks=[early_stop],
    verbose=1
)

# Explicaci√≥n
Las 3 primeras l√≠neas se importan y permiten construir un modelo secuencial con capas LSTM y Dense, y usar EarlyStopping para evitar sobreentrenar.

*Modelo LSTM*

model.add(Input(shape=(pasos, 1)))   # Capa de entrada expl√≠cita para evitar warning

A√±ades expl√≠citamente la capa de entrada, con una forma (pasos, 1):
- pasos: n√∫mero de pasos de tiempo (timesteps) que usa el LSTM.
- 1: n√∫mero de caracter√≠sticas por paso (feature size).
Esto previene un warning de TensorFlow que aparece si no se especifica la forma de entrada.
---

model.add(LSTM(50))  # Activaci√≥n por defecto 'tanh'

A√±ades una capa LSTM con 50 unidades (neuronas).
Esta capa procesa la secuencia de datos de entrada y extrae patrones temporales.
La funci√≥n de activaci√≥n predeterminada para la celda LSTM es tanh.
---

model.add(Dense(1))

A√±ades una capa densa final con 1 neurona, que hace la regresi√≥n (salida continua) y entrega la predicci√≥n para cada secuencia de entrada.
---

model.compile(optimizer='adam', loss='mse')

Compilas el modelo usando el optimizador Adam, que es un m√©todo eficiente para actualizar pesos.
La funci√≥n de p√©rdida es MSE (Mean Squared Error), que es adecuada para problemas de regresi√≥n.
---

early_stop = EarlyStopping(monitor='val_loss', patience=5)

Defines una callback para parar el entrenamiento si la m√©trica monitorizada (val_loss) no mejora durante 5 √©pocas consecutivas (patience=5).
Esto ayuda a evitar sobreentrenamiento y ahorra tiempo computacional.
---

history = model.fit(
    X_train_lstm, y_train_lstm,
    epochs=50,
    batch_size=32,
    validation_data=(X_test_lstm, y_test_lstm),
    callbacks=[early_stop],
    verbose=1
)

Empiezas el entrenamiento del modelo con los datos de entrenamiento (X_train_lstm, y_train_lstm).
Ejecuta hasta 50 √©pocas, con mini-batches de tama√±o 32.
Usa los datos de validaci√≥n (X_test_lstm, y_test_lstm) para medir el rendimiento despu√©s de cada √©poca.
Aplica la parada temprana con la callback early_stop.
verbose=1 muestra el progreso de cada √©poca en la consola.
---

Esta celda crea un modelo LSTM simple para un problema de predicci√≥n secuencial/regresi√≥n, con una capa LSTM y una capa densa final, entrena con parada temprana basada en la p√©rdida de validaci√≥n y muestra el progreso.

# Resultados
Epoch 1/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2s 6ms/step - loss: 0.0967 - val_loss: 0.0051
Epoch 2/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0052 - val_loss: 0.0041
Epoch 3/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0047 - val_loss: 0.0040
Epoch 4/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0045 - val_loss: 0.0043
Epoch 5/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0048 - val_loss: 0.0040
Epoch 6/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0045 - val_loss: 0.0039
Epoch 7/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0043 - val_loss: 0.0038
Epoch 8/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0043 - val_loss: 0.0037
Epoch 9/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0041 - val_loss: 0.0036
Epoch 10/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0042 - val_loss: 0.0035
Epoch 11/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0040 - val_loss: 0.0035
Epoch 12/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0040 - val_loss: 0.0034
Epoch 13/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0036 - val_loss: 0.0035
Epoch 14/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0037 - val_loss: 0.0033
Epoch 15/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0035 - val_loss: 0.0032
Epoch 16/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0038 - val_loss: 0.0031
Epoch 17/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0036 - val_loss: 0.0031
Epoch 18/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030
Epoch 19/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030
Epoch 20/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0033 - val_loss: 0.0030
Epoch 21/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0032 - val_loss: 0.0030
Epoch 22/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0033 - val_loss: 0.0029
Epoch 23/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0033 - val_loss: 0.0028
Epoch 24/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0031 - val_loss: 0.0030
Epoch 25/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0030 - val_loss: 0.0028
Epoch 26/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0030 - val_loss: 0.0030
Epoch 27/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0029 - val_loss: 0.0027
Epoch 28/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0031 - val_loss: 0.0027
Epoch 29/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0031 - val_loss: 0.0026
Epoch 30/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0029 - val_loss: 0.0027
Epoch 31/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0028 - val_loss: 0.0026
Epoch 32/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0030 - val_loss: 0.0026
Epoch 33/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0028 - val_loss: 0.0026
Epoch 34/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0030 - val_loss: 0.0026
Epoch 35/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0027 - val_loss: 0.0026
Epoch 36/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0029 - val_loss: 0.0027
Epoch 37/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0029 - val_loss: 0.0027
Epoch 38/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0029 - val_loss: 0.0026
Epoch 39/50
96/96 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - loss: 0.0030 - val_loss: 0.0029

# Explicaci√≥n resultados
*Evoluci√≥n de la p√©rdida (loss) y la p√©rdida de validaci√≥n (val_loss):*

- La p√©rdida inicial en la primera √©poca es relativamente alta (loss ‚âà 0.0967), pero baja r√°pidamente a partir de la segunda √©poca (loss ‚âà 0.0052), lo que indica que el modelo est√° aprendiendo r√°pido desde el principio.
- La p√©rdida de validaci√≥n tambi√©n empieza en un valor bajo (~0.0051) y sigue bajando progresivamente hasta valores alrededor de 0.0026 - 0.0030, lo que sugiere que el modelo est√° generalizando bien a datos que no ha visto durante el entrenamiento.

*Estabilidad y ausencia de sobreajuste:*

- La diferencia entre la p√©rdida de entrenamiento y la de validaci√≥n es muy peque√±a y se mantiene constante, lo cual es una se√±al positiva de que no hay un sobreajuste significativo.
- No se observa un aumento en la p√©rdida de validaci√≥n con las √©pocas, que normalmente indicar√≠a que el modelo comienza a memorizar y pierde capacidad de generalizaci√≥n.

*Calidad del ajuste:*

- Los valores de p√©rdida en torno a 0.0026 para un problema de regresi√≥n son generalmente buenos, especialmente si los datos est√°n normalizados. Esto indica que el modelo est√° haciendo predicciones bastante precisas.
- La evoluci√≥n muestra una ligera oscilaci√≥n, pero la tendencia general es a mejorar o mantenerse estable, lo cual es t√≠pico cuando el modelo alcanza un buen punto en el espacio de par√°metros.
-------------------------------------------------------------------------------------------------------------------------------

# Celda 10 - Visualizar la evoluci√≥n del error en entrenamiento y prueba

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='Error entrenamiento')
plt.plot(history.history['val_loss'], label='Error validaci√≥n')
plt.legend()
plt.show()

# Explicaci√≥n celda

Esta celda genera un gr√°fico que muestra c√≥mo evolucion√≥ el error del modelo durante el entrenamiento y la validaci√≥n a lo largo de las √©pocas.

plt.plot(history.history['loss'], label='Error entrenamiento')
plt.plot(history.history['val_loss'], label='Error validaci√≥n')
plt.legend()
plt.show()


history.history['loss']: es la lista del error de entrenamiento (MSE) para cada √©poca.
history.history['val_loss']: es la lista del error de validaci√≥n para cada √©poca.
Se plotean ambas curvas y se a√±ade una leyenda para identificar cada l√≠nea.
Finalmente, se muestra la gr√°fica.

# Resultados
Gr√°fica (image.png dentro de la carpeta documentaci√≥n)

# Explicaci√≥n resultados
- El error de entrenamiento comienza relativamente alto (~0.06), pero cae muy r√°pido en las primeras √©pocas hasta estabilizarse cerca de 0.0025-0.003.
- El error de validaci√≥n tambi√©n comienza bajo y se mantiene estable muy cerca del error de entrenamiento.
- Ambas curvas convergen, lo que indica que el modelo no est√° ni sobreajustando ni subajustando demasiado: tiene un buen ajuste.
- La baja diferencia entre ambos errores muestra que el modelo generaliza bien a datos nuevos.
- La forma plana despu√©s de pocas √©pocas indica que el entrenamiento se estabiliz√≥ r√°pido y probablemente la parada temprana detuvo el entrenamiento cuando ya no mejoraba la validaci√≥n.
